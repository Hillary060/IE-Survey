# 关系抽取调研——工业界

## 目录

  * [1. 任务](#1-任务)
     * [1.1. 任务定义](#11-任务定义)
     * [1.2. 数据集](#12-数据集)
     * [1.3. 评测标准](#13-评测标准)
     
  * [2. 方法总结](#2-方法总结)
     * [2.1. 基于模板的方法](#21-基于模板的方法)
        * [2.1.1. 基于触发词/字符串](#211-基于触发词/字符串)
        * [2.1.2. 基于依存句法](#212-基于依存句法)
     * [2.2. 监督学习](#22-监督学习)
        * [2.2.1. 机器学习](#221-机器学习)
        * [2.2.2. 深度学习 Pipeline vs Joint Model](#222-深度学习)
     * [2.3. 半监督/无监督方法](#23-半监督/无监督方法)
        * [2.3.1. Bootstrapping)](#231-Bootstrapping)
        * [2.3.2. 基于远程监督的方法](#232-基于远程监督的方法)
  * [3. 抽取工具应用](#3-抽取工具应用)
     * [3.1. TextRunner](#31-TextRunner)
     * [3.2. OLLIE开放三元组知识抽取](#32-OLLIE开放三元组知识抽取)
     * [3.3. IEPY](#33-IEPY)
     * [3.4. spaCy](#34-spaCy)
     * [3.5. NELL](#35-NELL)
     * [3.6. Deepdive](#36-Deepdive)
     * [3.7. Standford](#37-Standford)
  * [4.相关链接](#4-相关链接)
  * [5.参考资源](#5-参考资源)

## 1. 任务




### 1.1. 任务定义
自动识别句子中实体之间具有的某种语义关系。根据参与实体的多少可以分为二元关系抽取（两个实体）和多元关系抽取（三个及以上实体）。

通过关注两个实体间的语义关系，可以得到（arg1, relation, arg2）三元组，其中arg1和arg2表示两个实体，relation表示实体间的语义关系。

根据处理数据源的不同，关系抽取可以分为以下三种：

- 面向结构化文本的关系抽取：包括表格文档、XML文档、数据库数据等
- 面向非结构化文本的关系抽取：纯文本
- 面向半结构化文本的关系抽取：介于结构化和非结构化之间

根据抽取文本的范围不同，关系抽取可以分为以下两种：

- 句子级关系抽取：从一个句子中判别两个实体间是何种语义关系
- 语料（篇章）级关系抽取：不限定两个目标实体所出现的上下文

根据所抽取领域的划分，关系抽取又可以分为以下两种：

- 限定域关系抽取：在一个或者多个限定的领域内对实体间的语义关系进行抽取，限定关系的类别，可看成是一个文本分类任务
- 开放域关系抽取：不限定关系的类别

限定域关系抽取方法：

- 基于模板的关系抽取方法：通过人工编辑或者学习得到的模板对文本中的实体关系进行抽取和判别，受限于模板的质量和覆盖度，可扩张性不强
- 基于机器学习的关系抽取方法：将关系抽取看成是一个分类问题





### 1.2. 数据集
- **MUC关系抽取任务数据集**[官网](https://catalog.ldc.upenn.edu/LDC2001T02)

  MUC-7的五大评测任务分别是命名实体识别、共指消解、模板元素填充、模板关系确定和场景模板填充。数据语料主要来自新闻语料，限定领域为飞机失事报道和航天器发射事件报道。

- **ACE关系抽取任务数据集**[官网](http://projects.ldc.upenn.edu/ace/)

  MUC会议停开后，ACE将关系抽取任务作为一个子任务从2002至2007年共持续六年。关系抽取任务也被定义的更加规范和系统。其中，获得认可的一届关系抽取任务主要是ACE-2004，其数据来源于语言数据联盟（LDC），分成广播新闻和新闻专线两部分，总共包括451和文档和5702个关系实例。ACE2004提供了丰富的标注信息，从而为信息抽取中的实体识别、指代消解和关系抽取等子任务提供基准的训练和测试语料库。

- **TAC-KBP数据集**[TAC KBP（TAC Knowledge Base Population）](https://catalog.ldc.upenn.edu/LDC2018T03)
  TAC会议下的KBP评测下的ESF任务，可以视作是传统的关系抽取任务。该任务主要是抽取关于PER的25种属性和ORG的16种属性。主要是使用维基百科快照作为现有的知识库，从现有的新闻或者网络文本中获取关于实体的现有信息和更新信息，以构建知识库。如**TACRED**是一个拥有106264条实例的大规模关系抽取数据集，这些数据来自于每年比赛使用的语料库中的新闻专线和网络文本。

- **SemEval2010_task8**  [原始数据](http://semeval2.fbk.eu/semeval2.php?location=data)

  对于给定了的句子和两个做了标注的名词，从给定的关系清单中选出最合适的关系。数据集一共9种关系类别数，此外包含一类Other关系，含有6674实例数量

- **FewRel**[官网](https://thunlp.github.io/fewrel.html)

   是大规模精标注关系抽取数据集，由孙茂松教授领导的清华大学自然语言处理实验室发布。一共100种关系类别数，含有70000实例数量

- **NYT10** [原始数据](https://link.zhihu.com/?target=https%3A//cloud.tsinghua.edu.cn/f/11391e48b72749d8b60a/%3Fdl%3D1)

   **NYT-10**数据发布于Riedel et al, 2010[7]这篇论文中，其文本来源于纽约时报New York Times所标注的语料，命名实体是通过 Stanford NER 工具并结合 Freebase 知识库进行标注的。命名实体对之间的关系是链接和参考外部的Freebase知识库中的关系，结合远监督方法所得到的。

   


### 1.3. 评测标准

- P:  准确率

- R：召回率

- F1:  2 P*R/(P+R)

  

## 2. 方法总结

### 2.1. 基于模板的方法

**模板匹配**：是关系分类中最常见的方法，使用一个模板库对输入文本两个给定实体进行上下文匹配，如果满足模板对应关系，则作为实体对之间的关系。常见的模板匹配方法主要包括：

- **人工模板**：主要用于判断实体间是否存在上下位关系。上下位关系的自然语言表达方式相对有限，采用人工模板就可以很好完成关系分类。但对于自然语言表达形式非常多的关系类型而言，这就需要采取统计模板。
- **统计模板**：无须人工构建，主要基于搜索引擎进行统计模板抽取。具体地，将已知实体对作为查询语句，抓取搜索引擎返回的前n个结果文档并保留包含该实体对的句子集合，寻找包含实体对的最长字串作为统计模板，保留置信度较高的模板用于关系分类。



#### 2.1.1. 基于触发词/字符串
例：句子中上下位关系，比如hyponym(China; Asia countries)。从下面两个句子中都可以抽取出这种关系：

Asia countries, especially China, Japan, and India...

Asia countries, such as China, Japan, and India...

两个实体之间的especially和such as可以看做这种关系的特征。寻找更多表达这种关系的句子，构造规则模板，即可用于抽取构成上下位关系的实体，从而发现新的三元组。

#### 2.1.2. 基于依存句法的方法

使用NLP工具获取句子相关特征，对处理结果一般进行如下处理：

1. 对输入句子进行分词、词性标注、命名实体识别、依存分析等处理
2. 根据句子依存句法树结构进行规则匹配，每匹配一条规则就生成一个三元组
3. 根据扩展规则对抽取到的三元组进行扩展
4. 对三元组实体和触发词进一步处理抽取出关系

####  小结

手写规则的 **优点** ：

- 人工规则有高准确率(high-precision)
- 可以为特定领域定制(tailor)
- 在小规模数据集上容易实现，构建简单

**缺点**：

- 低召回率(low-recall)
- 特定领域的模板需要专家构建，要考虑周全所有可能的 pattern 很难，也很费时间精力
- 需要为每条关系来定义 pattern
- 难以维护
- 可移植性差



### 2.2. 监督学习

有监督的关系抽取方法：

- 基于特征工程的方法：需要显示地将关系实例转换成分类器可以接受的特征向量
- 基于核函数的方法：直接以结构树为处理对象，在计算关系之间距离的时候不再使用特征向量的内积而是用核函数
- 基于神经网络的方法：直接从输入的文本中自动学习有效的特征表示，是一个端到端的过程

#### 2.2.1. 机器学习
将关系抽取看成是一个基于构造特征的分类问题

**常见特征**：

- 实体特征，包括实体前后的词，实体类型，实体之间的距离等

- chunk，如 NP，VP，PP 这类短语

- 实体间的依存关系，实体间树结构的距离，及其他特定的结构信息

  

**标准流程**：

- 预先定义提取的关系集合
- 选择相关命名实体集合
- 寻找并标注数据
- 选择有代表性的语料库
- 标记命名实体
- 人工标注实体间关系
- 分割训练、开发、测试集
- 设计特征
- 选择并训练分类器
- 评估结果

通常会训练两个分类器，第一个分类器是 yes/no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。这样做的好处是通过排除大多数的实体对来加快分类器的训练过程，另一方面，对每个任务可以使用基于具体任务的特征集。常用的分类器包括 **MaxEnt、Naive Bayes、SVM** 等。



#### 2.2.2. 深度学习 Pipeline vs Joint Model

**Pipeline**

Pipeline方法先在句子中抽取实体、而后再抽取关系。即把实体识别和关系分类作为两个完全独立的过程，互不影响，关系的识别依赖于实体识别的效果。

...

**Joint Model**

现有联合抽取模型总体上有两大类：

1、**共享参数**的联合抽取模型

通过共享参数（共享输入特征或者内部隐层状态）实现联合，此种方法对子模型没有限制，但是由于使用独立的解码算法，导致实体模型和关系模型之间交互不强。

绝大数文献还是基于参数共享进行联合抽取的，这类的代表文献有：

2、**联合解码**的联合抽取模型

为了加强实体模型和关系模型的交互，复杂的联合解码算法被提出来，比如整数线性规划等。这种情况下**需要对子模型特征的丰富性以及联合解码的精确性之间做权衡**：

- 一方面如果设计精确的联合解码算法，往往需要对特征进行限制，例如用条件随机场建模，使用维特比解码算法可以得到全局最优解，但是往往需要限制特征的阶数。
- 另一方面如果使用近似解码算法，比如集束搜索，在特征方面可以抽取任意阶的特征，但是解码得到的结果是不精确的。

因此，需要一个算法可以在不影响子模型特征丰富性的条件下加强子模型之间的交互。

此外，很多方法再进行实体抽取时并没有直接用到关系的信息，然而这种信息是很重要的。需要一个方法可以**同时考虑一个句子中所有实体、实体与关系、关系与关系之间的交互**。



**Pipeline对比 Joint Model**：

相比于传统的Pipeline方法，联合抽取能获得更好的性能。虽然Pipeline方法易于实现，这两个抽取模型的灵活性高，实体模型和关系模型可以使用独立的数据集，并不需要同时标注实体和关系的数据集。但存在以下缺点：

1. 误差积累：实体抽取的错误会影响下一步关系抽取的性能。
2. 实体冗余：由于先对抽取的实体进行两两配对，然后再进行关系分类，没有关系的候选实体对所带来的冗余信息，会提升错误率、增加计算复杂度。
3. 交互缺失：忽略了这两个任务之间的内在联系和依赖关系。





### 2.3. 半监督/无监督方法

#### 2.3.1.  Bootstrapping

**Bootstrapping**：利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中并不断迭代。Bootstrapping的优点构建成本低，适合大规模的关系任务并且具备发现新关系的能力，但也存在对初始种子较为敏感、存在语义漂移、准确率等问题。Bootstrapping 如今在工业界中依旧是快速构建大规模知识图谱的重要方法。在实际使用中，可以考虑结合基于深度语义模型的关系抽取方法，进一步提高图谱召回。

**工业应用**：

bootstrapping比较常见的方法有**DIPRE**和**Snowball**。和**DIPRE**相比，**Snowball**通过对获得的模板pattern进行置信度计算，一定程度上可以保证抽取结果质量。

**DIPRE: Dual Iterative Pattern Expansion**

DIPRE是从HTML文档集合中提取结构化关系（或表格）的一种方法。 该方法在类似Web的环境下效果最好，其中的表格要提取的tuples往往会在反复出现在集合文档中一致的context内。 DIPRE利用这种集合冗余和内在的结构以提取目标关系并简化训练。

**DIPRE Pipeline**

DIPRE pattern由5-tuple *<order, urlprefix, left, middle, right>*组成，并通过将具有相等字符串分隔实体（*middle*）的共现种子tuples group在一起生成，然后将 *left* 字符串和 *right* 字符串分别设置为实体左侧和右侧上下文的最长公共子字符串。 *order* 反映了实体出现的顺序，*urlprefix* 设置为发现了 tuples 的源URL的最长公共子串。在从最初的种子 tuples 中生成一些 pattern 之后，DIPRE扫描包含 pattern 可匹配的文本片段的可用文档。随后，DIPRE生成新的tuples，并将它们用作新的“种子”。DIPRE反复迭代以上过程找到文档中的新 tuples 以识别新的可靠 patterns。

伪代码：

```text
收集具有关系R的一组种子tuples

迭代： 
1.找到包含这些种子tuples的句子 
2.查看种子tuples之间或周围的上下文，并泛化该上下文以生成patterns
3.用这些patterns找到更多种子tuples
```

**DIPRE样例**

![img](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/dipre_demo.png)

从 5 个种子 tuples 开始，找到包含种子的实例，替换关键词，形成 pattern，迭代匹配，就为 (author,book) 抽取到了 relation pattern，***x, by y***, 和 ***x, one of y’s***。

**DIPRE利弊**

**优点：**

1. 能够从非结构化文本中抽取出结构化的关系
2. 训练成本低，每个新场景只需要少量种子tuples。

**缺点：**

1. 依赖 HTML 标签
2. 缺少对新 pattern 和 tuples 的评估
3. 抽取结果噪声较多
4. 抽取结果 Recall 较低







#### 2.3.2.  基于远程监督的方法

远程监督算法基于一个非常重要的假设：**对于一个已有的知识图谱中的一个三元组（由一对实体和一个关系构成），外部文档库中任何包含这对实体的句子，在一定程度上都反映了这种关系。**基于这个假设，远程监督算法可以基于一个标注好的小型知识图谱，给外部文档库中的句子标注关系标签，相当于做了样本的自动标注，因此是一种半监督的算法。

**（1）多示例学习**：主要基于Bag的特征进行关系分类，主要代表文献包括PCNN[1]、Selective Attention over Instances[2]、Multi-label CNNs[3]、APCNNs[4]，其中Bag的表示主要方式和池化方式为：

[![img](https://camo.githubusercontent.com/d363bf0e22b90c0aa36841a715d1074363b64e65/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d39393633303831346162626437363862653564363132333665656464316131365f31343430772e706e67)](https://camo.githubusercontent.com/d363bf0e22b90c0aa36841a715d1074363b64e65/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d39393633303831346162626437363862653564363132333665656464316131365f31343430772e706e67)

**（2）强化学习**：在采用多示例学习策略时，可能会出现整个Bag包含大量噪声的情况。基于强化学习的CNN+RL[5]比句子级别和Bag级别的关系分类模型取得更好效果。

模型主要由样例选择器和关系分类器构成。样例选择器负责从样例中选择高质量的句子，采取强化学习方式在考虑当前句子的选择状态下选择样例；关系分类器向样例选择器反馈，改进选择策略。

[![img](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/CNN%2BRL.png)

**（3）预训练机制**：采取“Matching the Blank[6]”方法，首次在预训练过程中引入关系分类目标，但仍然是自监督的，没有引入知识库和额外的人工标注，将实体metion替换为「BLANK」标识符。

- 该方法认为包含相同实体对的句子对为正样本，而实体对不一样的句子对为负样本。如图，rA和rB构成正样本，rA和rC构成rB和rC构负样本。
- 不同于传统的远程监督，该方法训练中不使用关系标签，采用二元分类器对句子对进行相似度计算。预训练的损失包含2部分：MLM loss 和 二元交叉熵关系损失。
- 在FewRel数据集上，不进行任何tuning就已经超过了有监督的结果。

[![img](https://camo.githubusercontent.com/29dfe763b28ca39cd2878098025c5ae4b376b601/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d39383831393332666538623737613939623066663536376139353835303035305f31343430772e706e67)](https://camo.githubusercontent.com/29dfe763b28ca39cd2878098025c5ae4b376b601/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d39383831393332666538623737613939623066663536376139353835303035305f31343430772e706e67)





## 3. 抽取工具应用

### 3.1. TextRunner

**TEXTRUNNER**三个关键步骤：

Open Information Extraction from the Web(TextRunner, 2007，华盛顿大学)

- **Self-Supervised Learner**：构造训练数据集，学习一个贝叶斯分类器，判断(e*i, relation words, e_*j)是否是可信的关系
- **Single-Pass Extractor**：输入一句话，产生所有可能的候选三元组，使用分类器判别，保留可信的三元组
- **Redundancy-Based Assessor**：统计(e_*i, relation words, e_*j)发生在不同句子中的频次，保留高频词的结果作为最终结果

**Self-Supervised Learner**:

- **parsing** :在一个小的数据集进行**语法解析**，解析句子中的名词短语

- **构造三元组**：将名词短语作为可能的实体e_i，两个名词短语之间的词语作为关系，构成三元组候选集合

- **使用约束构造正负样本**： 满足下述三个条件的作为正样本

- - e*i e_j存在依赖路径，并且路径长度小于一定的值*
  - The path from ei to ej along the syntax tree does not cross a sentence-like boundary (e.g. relative clauses)
  - e*i e*j都不是代词

- **训练分类器**：三元组 ![[公式]](https://www.zhihu.com/equation?tex=%28e_i%2C+r_%7Bi%2Cj%7D%2C+e_j%29) ,将三元组特征化，训练一个贝叶斯分类器；特征有

- - presence of part-of-speech tag sequences in the relation ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bi%2Cj%7D)
  - the number of tokens in ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bi%2Cj%7D)
  - the number of stopwords in ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bi%2Cj%7D)
  - whether or not an object e is found to be a proper noun
  - the part-of-speech tag to the left of ei
  - the part-of-speech tag to the right of ej .

**Single-Pass Extractor**:

输入一个句子，处理过程如下

- **先进行词性标注**，然后使用lightweight noun phrase chunker识别名词短语
- 识别**名词短语之间的词语**作为关系表示
- 使用分类器进行分类，判别这个三元组候选是否可信

**Redundancy-based Assessor**：

- 会通过启发式的规则归一化关系短语，比如去除不必要的修饰词语
- 统计三元组的频数，如果这个三元组是从k个不同的句子中抽取得到的话



### 3.2. OLLIE开放三元组知识抽取

OLLIE支持基于语法依赖树的关系抽取。流程图如下，主要包含三个步骤

- **Constructing a Bootstrapping Set**：使用REVERB已经抽取到的高质量的三元组作为Seed Tuples，使用Seed Tuple抽取包含这些seed tuple的句子，构造一个比较大的训练数据集
- **Open Pattern Learning**：基于语法解析，使用训练数据集学习open pattern templates/抽取模式模板
- **Pattern Matching for Extraction**：使用学习到的open pattern templates来抽取新的三元组

![img](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/OOLLIE.png)



### 3.3. IEPY

开源项⽬：https://github.com/machinalis/iepy

主要做关系抽取：**IEPY is an open source tool for Information Extraction focused on Relation Extraction. **

**工具特征**：

1.带web-UI的语料标注⼯具。

2.基于主动学习的关系抽取的⼯具。

3.基于规则的关系抽取⼯具。

4.有web-UI帮助使⽤：

1)⽅便⾮专业⽤户使⽤部分功能。

2)允许分布式的⽤户输⼊。

通过斯坦福CoreNLP做共指解析。

5.可以基于开源代码作二次开发。



#### 使用

**安装**：

作为Python包安装，pip install iepy, 并下载第三⽅数据 iepy --download-third-party-data 

使⽤：

**1**创建项⽬

iepy --create <project_name> 

**2**导⼊要抽取的语料

python bin/csv_to_iepy.py data.csv 

**3**数据预处理（ text tokenization, sentence splitting, lemmatization, part-of-speech tagging, and named entity recognition）

python bin/preprocess.py 

**4**启动**web-ui**查看项⽬

python bin/manage.py runserver 

**5**进⾏**active learning(**需要在⾃⼰标⼀些数据**)**或**rule-based(**写规则**)**关系抽取

**6**在界⾯上标⼀些测试集来验证抽取效果。

![image-20200917104922545](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/NELL.png)

#### 总结

**功能**：

对于要处理的语料导⼊到项⽬⾥，提供前⾯的预处理和两种⽅式的关系抽取。Active 

Learning的需要⾃⼰定义关系和标⼀些数据。Rule-based的需要⾃⼰写规则。也封装好了

⼀些脚本⽅便的做导⼊数据、预处理、规则检查等。

**使⽤⽅式**：

python包 + webUI，类似pyspider。可以⽤界⾯来定义关系和查看抽取结果、标注测试集

等。不过还是需要⽤命令⾏来load数据，预处理等，这部分其实也可以在界⾯实现。

**评价**：

由于开发的时间早，抽取的⽅法不新，也没有预先在⼤数据集上训练得到通⽤领域关系抽

取的模型，需要⽤户⾃⼰定义关系并标注数据。

每⼀个抽取任务创建⼀个project，使⽤web界⾯⽅便操作和可视化，感觉我们做领域迁移

也可以采⽤这种⽅法，把流程固定，然后通过创建不同的project，导⼊不同的数据，定义

不同的关系，然后⽤webUI进⾏可视化和⼈⼯操作。





### 3.4. spaCy

**3.4.1** 介绍

**⼯业级的**NLP**⼯具**：功能很强⼤，不⽌是做Information Extraction，⽤Cython优化，各种处理超级快（官⽹fastest in the world），能⽤于在真实场景和产品⾥的。适合对⽤于Deep Learning的⽂本进⾏预处理。能和TensorFlow, PyTorch, scikit-learn, Gensim 等深度学习框架⽆缝衔接。



**3.4.2 工具特点**：

- ⽆损的tokenization 
- 命名实体识别
- ⽀持53+语⾔
- 支持11种语⾔上的17个统计模型
- 预训练好的词向量
- SOTA的速度
- ⽅便与深度学习集成
- POS标注
- 带标记的依存句法分析
- 句法驱动的句⼦分割
- 内置⽤于语法和NER的可视化⼯具
- ⽅便的字符串->哈希值映射
- 导出到numpy数组
- ⾼效的⼆进制序列化
- ⽅便的模型打包和部署
- 稳健，经过严格评估的准确性



#### 3.4.3 总结

功能：

并⾮专⻔做信息抽取，也没有抽取关系的功能。封装了NLP相关的基础⼯作，并优化了速度以⽤于真实产品。

同时也允许⽤户⾃⼰训练模型load后使⽤。

使⽤⽅式：

python包+load下载的模型。

评价：

功能很多很实⽤，定位在于做深度学习前⾯的⽂本预处理，且优化速度。使⽤⽅式和很多⼯具⼀样，使⽤python包，封装好各种通⽤功能和接⼝，再通过加载不同的模型实现使⽤在不同领域、语⾔或者应对⽅法改进的情况。





### 3.5 NELL

**3.1** 介绍

永恒语⾔学习：

Never-ending Language Learning。不断学习语⾔知识，2010年提出。

**architecture**：

![image-20200917110152465](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/NELL_ARC.png)

![image-20200917111521876](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/NELL_PRO.png)



流程：

利⽤少量标记样本集合训练学习模型, 然后⽤该模型去标记更多样本。（需要偶尔⼈⼯标注）。运⽤多视⻆学习(multi-view learning)分别从⽂本背景信息、网页结构信息、构词法特征以及规则学习4个⻆度进⾏新知识抽取和知识库的扩充。



**3.5** 总结

评价：

可以借鉴这种⽅式扩充构建好的知识库，对于通⽤领域知识库可以在⽹⻚⽂本上抽取，特

定领域的可以喂相关领域的⽂档或者爬取到的⽹⻚⽂本。信息抽取⼯具应该不包含这个功能，⽽是通过这个⼯具的使⽤能够实现这种功能。


### 3.6 Deepdive
官网地址：[http://deepdive.stanford.edu/](http://deepdive.stanford.edu/)

[Deepdive](http://deepdive.stanford.edu/)是stanford大学InfoLab实验室开发的一个开源知识抽取系统，它通过弱监督学习，从非结构化的文本中提取结构化的关系数据。DeepDive用于提取实体之间的复杂关系并推断涉及这些实体的事实。在使用Deepdive进行关系抽取的时候，使用者不需要关心算法，只需要指定实体的特征，Deepdive通过联合推理，即可得出两个实体之间有关系的概率。

Deepdive的优点如下：
（1）可以处理带噪声的数据，用户可以通过对断言设置置信度来矫正噪声
（2）可以通过使用已有的领域知识来指导推理结果，通过用户反馈的结果来提高预测的准确率
（3）使用远监督技术，不需要或仅需要少量数据即可完成抽取

抽取流程如下：
![image](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/deepdive.jpg)

一个中文抽取示例：股权抽取 [https://zhuanlan.zhihu.com/p/43143663](https://zhuanlan.zhihu.com/p/43143663)

### 3.7 Stanford

官网地址：[https://stanfordnlp.github.io/CoreNLP](https://stanfordnlp.github.io/CoreNLP/)

Stanford CoreNLP是斯坦福大学提供的自然语言处理工具，是由Java写成的，可通过使用Web服务与CoreNLP进行交互，从而使用python等其他语言进行编程，目前提供python接口可直接安装使用，支持多种语言。

Open IE（开放信息提取）是指从纯文本中提取关系元组，与其他提取不同的是，Open IE 不需要提前定义schema，主要利用语言结构进行开放领域信息抽取。Stanford Open IE是Stanford CoreNLP包中的一个开放领域信息抽取模块，该模块的抽取思路如下：

1、先将句子分成几个子句（学习一个分类器）

2、最大程度地缩短每个子句，产生一组所需的句子片段

3、从片段中提取三元组（自然逻辑）

相关论文链接：[https://nlp.stanford.edu/pubs/2015angeli-openie.pdf](https://nlp.stanford.edu/pubs/2015angeli-openie.pdf)

Relation Extractor（关系抽取）是Stanford CoreNLP中的另一个处理模块，用于抽取特定领域的关系。目前支持Live_In, Located_In, OrgBased_In, Work_For, and None这几种关系。用户可以使用提供的接口使用自己的数据集训练自己的模型，从而实现特定领域的关系抽取。该模块的抽取思路如下：

1、数据预处理：tokenization，part of speech tagging

2、实体识别（标注）

3、使用多类逻辑回归分类器对关系进行分类

Stanford Open IE& Relation Extractor对比

| 模块               | 领域     | 使用方法                                             | 用户使用                                       |
| ------------------ | -------- | ---------------------------------------------------- | ---------------------------------------------- |
| Open IE            | 开放领域 | 下载StandfordCoreNLP包                               | 可以使用java或者其他语言进行服务器与来进行编码 |
| Relation Extractor | 特定领域 | 下载StandfordCoreNLP包，用户可自行训练特定领域的模型 | 可以使用java或者其他语言与服务器交互来进行编码 |










## 4. 相关文献

1. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks. EMNLP
2. Attention over Instances (Lin 2016)
3. Relation Extraction with Multi-instance Multi-label Convolutional Neural Networks.
4. Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions
5. Reinforcement Learning for Relation Classification from Noisy Data
6. [Matching the Blanks: Distributional Similarity for Relation Learning]( https://arxiv.org/pdf/1906.03158.pdf)
7. Riedel, Sebastian, Limin Yao, and Andrew McCallum. "Modeling relations and their mentions without labeled text."*Joint European Conference on Machine Learning and Knowledge Discovery in Databases*. Springer, Berlin, Heidelberg, 2010.

## 5. 参考资源

[https://zhuanlan.zhihu.com/p/139485679](https://zhuanlan.zhihu.com/p/139485679)

[https://zhuanlan.zhihu.com/p/77868938](https://zhuanlan.zhihu.com/p/77868938)
